# Udacity_Data_Analysis_Professional_Track_Projects

## The first Project "BikeShare"
In this project, the purpose is to make use of Python to explore data related to bike share systems for three major cities in the United States: Chicago, New York City and Washington.
I wrote a code to import the data and answer questions about it by computing descriptive statistics.
I also wrote a script that takes in raw input to create an interactive experience in the terminal to present these statistics.

## The Second Project "We Rate Dogs"
In this project, the purpose is to wrangle WeRateDogs Twitter data to create analyses and visualizations.

Data wrangled through 3 main steps:


[1] Gathering data, through:

• Twitter Archive Enanced.csv file : given.
• Tweet-json.txt : Twitter API.
• image-predictions.tsv : downloaded from a given URL using requests.

[2] Assessing data, through:

• Visually: by inspection the three dataframes heads and tails to find the obvious quality and tidiness issues.
•	Programmatically: by using codes and functions such as: info(), value_counts() and duplicated(), ... etc.

[3] Cleaning data:

• From quality issues such as: columns names typos, inaccurate data, wrong columns data type, ... etc.
• From tidiness issues such as: the whole data is separated into 3 different dataframes, creating 2 obvious cloumns from 9 separated columns, ... etc.


After data wrangling, it's analyzied and visualized with plots.
